\documentclass{article}

\include{header}

\def\LaTeXe{c}

\title{Collaborative Filtering for the NetFlix Challenge}
\author{Masahiro Ono and Yang Zhang}

\begin{document}

\maketitle

\section{Introduction}

For our project, we implemented and evaluated several approaches to
collaborative filtering a subset of the NetFlix Challenge dataset.

\paragraph{Definition of the Rating Matrix}
There are $n_U$ users and $n_M$ movies.  The {\em ratings matrix}
$\mat{R}$ is a $n_M$-by-$n_U$ matrix whose rows correspond to users
and columns correspond to movies, such that entry $r_{i,j} \in
\range{5}$ is the rating given by user $i$ to movie $j$.

The NetFlix dataset is large: it contains 480,189 users, 17,770
movies, and 100,480,507 ratings. MATLAB's in-memory data management is
not amenable to datasets of such scale; hence, we TODO describe how we
got this small fully packed rating matrix, and why we didn't choose to
go with the full netflix dataset.

\paragraph{TODO: Perfomance measure: room mean square error(RMSE)}

\section{Mixture Model}

We use a mixture model to cluster together ratings based on user types
and movie types. There are various other mixture models for
collaborative filtering; this model is known as the Joint Mixture
Model, and is the one presented in 6.867 lecture. TODO citation

For this part of our project, we rigorously derived the E-M algorithm,
implement the algorithm in MATLAB, and analyzed its results. The
following sections are organized as follows. First, we describe and
justify the model. Second, we derive the E-M algorithm. Third, we
evaluate its performance by using TODO 

\subsection{Overview}

We say that {\em each user} has a distribution over user types (e.g.,
mostly romantic, a bit of an intellectual), and each movie has a
distribution over movie types (mostly horror, some action). Each pair
of user type and movie type has a distribution over ratings (e.g.,
romantics tend to give horrors low ratings). The likelihood of
our model given the parameters is then
\begin{align}
  \LL{D}{\theta}
  =& \PP{ R_{1,1} = r_{1,1}, \dots, R_{n_U,n_M} = r_{n_U,n_M} }{
    \theta } \\
  =& \prod_{i,j} \sum_{u,m} \left[
    \begin{aligned}
      & \PP{ R_{i,j} = r_{i,j} }{ U_{i,j} = u, M_{i,j} = m,
        \theta^R_{u,m} } \cdot \\
      & \PP{ U_{i,j} = u }{ \theta^U_i } \cdot
      \PP{ M_{i,j} = m }{ \theta^M_j }
    \end{aligned} \right] \\
  =& \prod_{i,j} \sum_{u,m} \theta^R_{u,m}(r) \cdot \theta^U_i(u) \cdot \theta^M_j(m)
\end{align}
We see that there are three sets of parameters, and our approach is to
use an E-M algorithm to perform maximum likelihood estimation of these
parameters.

Each cell has its own user and movie type. What does all this mean?
Intuitively, we can think of each cell as the result of an {\em act}
of rating. Hence, every time a user rates a movie, we are randomly
sampling from among the user's multiple personalities (e.g., the
romantic in the user was rating this movie). We are also sampling from
among the movie's multiple aspects (the user saw this movie as a
horror movie). We will loosely use the term ``rating'' to mean either
the act of the rating or the rating value itself; hopefully the
meaning remains clear from the context.

TODO? discuss why the alternative model doesn't work

Figure (TODO) shows the . TODO insert graphical model

\subsection{E-M Algorithm}

TODO reformat below equations

\subsubsection{M-step with complete data}

To derive the E-M algorithm, it is helpful to start by assuming that
we have ``complete data''---that is, for each rating $i,j$, we know
precisely which user type $u$ and movie type $m$ the rating belongs
to.  With this information, we can directly and analytically find the
parameters that maximize the likelihood of the data.  We can
equivalently optimize the log-likelihood: $\arg \max_\theta
\LL{D}{\theta} = \arg \max_\theta \log \LL{D}{\theta}$.
\begin{align}
  \LLL{D}{\theta} =& \log \LL{D}{\theta} \\
  =& \sum_{i,j} \left[
    \begin{aligned}
      & \log \PP{R_{i,j} = r_{i,j}}{U_{i,j} = u_{i,J}, M_{i,j} = m_{i,j},
        \theta^R} + \\
      & \log \PP{U_{i,j} = u_{i,j}}{\theta^U_i} + \\
      & \log \PP{M_{i,j} = m_{i,j}}{\theta^M_j}
    \end{aligned}
  \right] \\
  =& \sum_{i,j} \left[
    \log \theta^R_{u_{i,j},m_{i,j}}(r_{i,j}) +
    \log \theta^U_i(u_{i,j}) +
    \log \theta^M_j(m_{i,j})
  \right] \\
  =& \sum_{r,u,m,i,j} n_{r,u,m,i,j} \left[
    \log \theta^R_{u,m}(r) + \log \theta^U_i(u) + \log \theta^M_j(m)
  \right]
\end{align}
Above, $n_{r,u,m,i,j}$ is 1 if rating $i,j$ has rating value $r$, user
type $u$, and movie type $m$, and 0 otherwise.

Implicit throughout the previous equations were a number of
constraints due to the fact that we're dealing with probabilities. In
particular,
\begin{align}
\sum_r \theta_{u,m}(r) =& 1 &
\sum_u \theta_i(u) =& 1 &
\sum_m \theta_j(m) =& 1
\end{align}
To allow ourselves to optimize the equations analytically, we can
incorporate these into the equation by using LaGrange multipliers
($\lambda$s below):
\begin{align}
  \begin{aligned}
    \sum_{r,u,m,i,j} n_{r,u,m,i,j} \left[
      \log \theta^R_{u,m}(r) + \log \theta^U_i(u) + \log \theta^M_j(m)
    \right] & \\
    \mathbin{+} \lambda^R_{u,m} \left( 1 - \sum_r \theta^R_{u,m}(r) \right)
    & \forall u,m \\
    \mathbin{+} \lambda^U_i \left( 1 - \sum_u \theta^U_i(u) \right)
    & \forall i \\
    \mathbin{+} \lambda^M_j \left( 1 - \sum_m \theta^M_j(m) \right)
    & \forall j
  \end{aligned}
\end{align}

To find the maximizing value of a parameter, we find the zeros of the
partial derivative with respect to that parameter. This turns out to
be straightforward for the above expression, because the parameters
are in separate terms, so that many terms in the sums and quantifiers
``disappear.''

For all $u,i$,
\begin{align}
  0 =& \frac{ \partial \LLL{D}{\theta} }{ \partial \theta^U_i(u) }
  = \sum_{r,m,j} \frac{ n_{r,u,m,i,j} }{ \theta^U_i(u) } - \lambda^U_i
  \Rightarrow &
  \theta^U_i(u) =& \frac{ \sum_{r,m,j} n_{r,u,m,i,j} }{ \lambda^U_i } \\
  1 =& \sum_u \theta^U_i(u) 
  = \sum_u \frac{ \sum_{r,m,j} n_{r,u,m,i,j} }{ \lambda^U_i }
  \Rightarrow &
  \lambda^U_i =& \sum_{r,u,m,j} n_{r,u,m,i,j} \\
  & \therefore \theta^U_i(u)
  = \frac{ \sum_{r,m,j} n_{r,u,m,i,j} }{ \sum_{r,u,m,j} n_{r,u,m,i,j} }
  = \frac{ n_{u,i} }{ n_M }
\end{align}
This makes intuitive sense, since $\theta^U_i(u) = \PP{U_{i,j} =
u}{\theta^U_i}$ for any movie $j$. The probability that we see the
romantic in a user is the number of her other ratings where it was the
romantic in her speaking, over her total number of ratings.

Similarly (almost symmetrically), we find:
\begin{align}
\forall m,j,\ \theta^M_j(m) =& \frac{ n_{m,j} }{ n_U } &
\forall r,u,m,\ \theta^M_j(m) =& \frac{ n_{r,u,m} }{ n_{u,m} }
\end{align}

However, we do not have complete data---we do not have the above
counts, since we do not know the user-/movie-type assignments. Since
the incomplete data does not yield an analytical solution, we must use
a numerical approach, namely an E-M algorithm. This algorithm
iteratively updates the parameters in the M-step based on
intermediately calculated posteriors in the E-step. Essentially, we
use the posteriors to find the {\em expected} counts in the above
equations.

\subsubsection{E-step}

For all $i \in \range{n_M}, j \in \range{n_M}$, we calculate the
posterior.
\begin{align}
& \PP{ U_{i,j} = u, M_{i,j} = m }{ R = \mat{R}, \theta } \\
=& \PP{ U_{i,j} = u, M_{i,j} = m }{ R_{i,j} = r_{i,j}, \theta^U_i,
  \theta^M_j, \theta^R }
&&
\text{by
the independencies in the graphical model's moralized ancestral graph
(TODO figures?)} \\
=& \frac{1}{Z} \left(
\begin{aligned}
& \PP{R_{i,j} = r_{i,j} }{U_{i,j} = u, M_{i,j} = m, \theta^R} \\
& \PP{U_{i,j} = u, M_{i,j} = m}{\theta^U_i, \theta^M_j}
\end{aligned} \right)
&& \text{by Bayes' rule, where $Z = \PP{R_{i,j} = r_{i,j}}{\theta}$ is a
  normalizing constant defined below} \\
=& \frac{1}{Z} \left(
\begin{aligned}
& \PP{R_{i,j} = r_{i,j} }{U_{i,j} = u, M_{i,j} = m, \theta^R} \\
& \PP{U_{i,j} = u }{\theta^U_i}
  \PP{M_{i,j} = m }{\theta^M_j}
\end{aligned} \right)
&& \text{by the independencies in the graphical model's
  moralized ancestral graph} \\
=& \frac{1}{Z} \theta^R_{u,m}(r_{i,j}) \theta^U_i(u) \theta^M_j(m)
\end{align}
Above,
\begin{align}
  Z =& \sum_{u,m} \PP{U = u, M = m}{R = r, \theta^U_i, \theta^M_j,
    \theta^R}
\end{align}

For any $i,j$,
letting $U = U_{i,j}, M = M_{i,j}, R = R_{i,j}$,
we can marginalize the above joint distribution over $M$ and $U$
to get the distributions over $U$ and $M$, respectively:

\begin{align}
  \PP{U = u}{R = r, \theta^U_i, \theta^M_j, \theta^R}
  =& \sum_m \PP{U = u, M = m}{R = r, \theta^U_i, \theta^M_j, \theta^R}
\\
  \PP{U = u}{R = r, \theta^U_i, \theta^M_j, \theta^R}
  =& \sum_m \PP{U = u, M = m}{R = r, \theta^U_i, \theta^M_j, \theta^R}
\end{align}

\subsubsection{M-step}

Now we can use these posterior values to find expected counts in order
to update the parameters.

For all $i \in \range{n_U}$, for any $j \in \range{n_M}$,
\begin{align}
  \E{n_{u,i}}{\mat{R}, \theta}
  =& \E{ \sum_{r,m,j} n_{r,u,m,i,j} }{R = \mat{R}, \theta} \\
  =& \sum_{r,m,j} \E{ n_{r,u,m,i,j} }{R = \mat{R}, \theta} \\
  =& \sum_{r,m,j} \left[
    0 + 1 \cdot \PP{ R_{i,j} = r, U_{i,j} = u, M_{i,j} = m }{R = \mat{R}, \theta}
  \right] \\
  =& \sum_j \PP{U_{i,j} = u}{R = \mat{R}, \theta}
  && \text{marginalized $M$, observed $R$} \\
  =& \sum_j \PP{U_{i,j} = u}{R_{i,j} = r_{i,j}, \theta^R_{u,m},
    \theta^U_i, \theta^M_j}
  && \text{independencies in graph} \\
  {\theta^U_i}'(u)
  =& \E{ \frac{ n_{u,i}}{ n_M } }{\theta} && \text{TODO reference the
    equation num} \\
  =& \frac{1}{n_M} \sum_j \PP{U_{i,j} = u}{ R_{i,j} = r_{i,j}, \theta^R_{u,m},
    \theta^U_i, \theta^M_j }
  && \text{weighted sum over the row}
\end{align}

Similarly, for all $j \in \range{n_M}$,
\begin{align}
  {\theta^M_j}'(m) =&
  \frac{1}{n_U} \sum_i \PP{M = m}{
    R_{i,j} = r_{i,j}, \theta^R_{u,m}, \theta^U_i, \theta^M_j}
\end{align}

Finally, for all $u \in \range{k_U}, m \in \range{k_M}$,
\begin{align}
  {\theta^R_{u,m}}'(r)
  =& \E{ \frac{n_{r,u,m}}{n_{u,m}} }{\theta} \\
  =& \frac{ \E{n_{r,u,m} }{\theta} }{ \E{n_{u,m}}{\theta} }
  && \text{TODO how to justify this?} \\
  =& \frac{\sum_{i,j: r_{i,j} = r} \PP{U_{i,j} = u, M_{i,j} = m}{
      R_{i,j} = r_{i,j}, \theta^R_{u,m}, \theta^U_i, \theta^M_j}
  }{ \sum_{i,j} \PP{U_{i,j} = u, M_{i,j} = m}{
      R_{i,j} = r_{i,j}, \theta^R_{u,m}, \theta^U_i, \theta^M_j} } \\
\end{align}

\subsection{Results}

TODO This turns out to work well.



\include{hiro}



\section{Appendix}

\subsection{Mixture Models}

Here are the variables we're using for the mixture models:

\begin{itemize}
\item $\theta$: the entire set of parameters. TODO explain the sharing
  (but not here)
  \begin{itemize}
  \item $\theta^U_i(u)$: the probability distribution over user types
    $u$ for a user $i$ (think
    of this as a table). This is shared by all user-movie ratings for
    user $i$.
  \item $\theta^M_j(m)$: the probability distribution over movie
    types $m$ for a movie $j$. This is shared by all user-movie ratings for movie $j$.
  \item $\theta^R_{u,m}(r)$: the probability distributions over
    ratings $r$ for user type $u$ and movie type $m$. This is shared
    by all user-movie ratings $i,j$.
  \end{itemize}
\item Dimensions
  \begin{itemize}
  \item $n_U$: number of users
  \item $n_M$: number of movies
  \item $k_U$: number of user types
  \item $k_M$: number of movie types
  \end{itemize}
\item Indexes. This allows us to omit ranges in sums and quantifiers.
  \begin{itemize}
  \item $i$: generally used to index over users
  \item $j$: generally used to index over movies
  \item $u$: generally used to index over user types
  \item $m$: generally used to index over movie types
  \end{itemize}
\item Random variables
  \begin{itemize}
  \item $U_i$: the user type of user $i$
  \item $M_j$: the movie type of movie $j$
  \item $R_{i,j}$: the rating user $i$ gave for movie $j$
  \end{itemize}
\end{itemize}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{comment}

\subsection{Mixture Model 1}

TODO insert graphical model

The likelihood of our model is:

\begin{align*}
  L \left( D \mid \theta \right)
  =& \PP{ R_{1,1} = r_{1,1}, \dots, R_{n,m} = r_{n,m} }{ \theta } \\
  =& \prod_{i,j} \PP{ R_{i,j} = r_{i,j} }{ \theta } \\
  =& \prod_{i,j} \sum_{u,m}
  \PP{ R_{i,j} = r_{i,j} }{ U_i = u, M_j = m, \theta_R }
  \PP{ U_i = u }{ \theta_U }
  \PP{ M_j = m }{ \theta_M } \\
  =& \prod_{i,j} \sum_{u,m} \theta_R(r \mid u,m) \theta_U(u) \theta_M(m)
\end{align*}

E-step:

\begin{align*}
  \forall i,j:
  & \PP{ U_i = u, M_j = m }{ R_{i,j} = r_{i,j}, \theta } \\
  =& \frac{
    \PP{ U_i = u, M_j = m, R_{i,j} = r_{i,j} }{ \theta }
  }{
    \PP{ R_{i,j} = r_{i,j} }{ \theta }
  } \\
% P(U,M|R) = P(U,M,R) = P(R|U,M) P(U,M)
  =& \frac{
    \PP{ U_i = u, M_j = m }{ \theta }
    \PP{ R_{i,j} = r_{i,j} }{ U_i = u, M_j = m, \theta }
  }{
    \sum_{u',m'}
    \PP{ U_i = u', M_j = m' }{ \theta }
    \PP{ R_{i,j} = r_{i,j} }{ U_i = u', M_j = m', \theta }
  } & \textrm{Bayes' rule} \\
  =& \frac{
    \PP{ U_i = u }{ \theta_U }
    \PP{ M_i = m }{ \theta_M }
    \PP{ R_{i,j} = r_{i,j} }{ U_i = u, M_j = m, \theta }
  }{
    \sum_{u',m'}
    \PP{ U_i = u' }{ \theta_U }
    \PP{ M_i = m' }{ \theta_M }
    \PP{ R_{i,j} = r_{i,j} }{ U_i = u', M_j = m', \theta }
  } & \textrm{Bayes' rule} \\
  =& \PP{}{}
\end{align*}

M-step:

\begin{align*}
\forall i,j: &
\PP{ R_{i,j} = r }{ U_i = u, M_j = m, \theta_R } \\
\forall i: &
\PP{ U_i = u }{ \theta_U } \\
=& \frac{
  \N{cells with user type $i$}
}{
  \N{cells}
}\\
=& \N{}
\end{align*}

TODO finish/correct above equations

\end{comment}
